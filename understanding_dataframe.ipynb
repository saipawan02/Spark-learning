{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('practice').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('test1.csv', header= True, inferSchema=True)\n",
    "# inferSchemastr or bool, optional. infers the input schema automatically from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+----------+\n",
      "|_c0|names|age|experience|\n",
      "+---+-----+---+----------+\n",
      "|  0|  sai| 12|         1|\n",
      "|  1|pawan| 24|         2|\n",
      "|  2|    d| 36|         3|\n",
      "+---+-----+---+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/25 20:41:46 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , names, age, experience\n",
      " Schema: _c0, names, age, experience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/dsaipawan/Documents/python-learing/big-data/test1.csv\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- names: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|names|experience|\n",
      "+-----+----------+\n",
      "|  sai|         1|\n",
      "|pawan|         2|\n",
      "|    d|         3|\n",
      "+-----+----------+\n",
      "\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df_name_exp = df.select(['names', 'experience'])\n",
    "df_name_exp.show()\n",
    "\n",
    "print(type(df_name_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_c0', 'int'), ('names', 'string'), ('age', 'int'), ('experience', 'int')]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/25 20:41:46 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , names, age, experience\n",
      " Schema: _c0, names, age, experience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/dsaipawan/Documents/python-learing/big-data/test1.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+-----+----+----------+\n",
      "|summary|_c0|names| age|experience|\n",
      "+-------+---+-----+----+----------+\n",
      "|  count|  3|    3|   3|         3|\n",
      "|   mean|1.0| NULL|24.0|       2.0|\n",
      "| stddev|1.0| NULL|12.0|       1.0|\n",
      "|    min|  0|    d|  12|         1|\n",
      "|    max|  2|  sai|  36|         3|\n",
      "+-------+---+-----+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Columns in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column<'names'> <class 'pyspark.sql.column.Column'>\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/71/c7pdh8bj3p1chk4tv474y1g80000gn/T/ipykernel_16639/4111862367.py\", line 9, in <module>\n",
      "    names.show()\n",
      "TypeError: 'Column' object is not callable\n"
     ]
    }
   ],
   "source": [
    "# Picking up a singel column will change the datatype to column not dataframe.\n",
    "names = df_name_exp['names']\n",
    "print(names, type(names))\n",
    "\n",
    "try:\n",
    "    # Show only works on the dataframe not on columns\n",
    "    names.show()\n",
    "except TypeError as e:\n",
    "    print(traceback.print_exception(e))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+----------+------------------------+\n",
      "|_c0|names|age|experience|Experience after 2 years|\n",
      "+---+-----+---+----------+------------------------+\n",
      "|  0|  sai| 12|         1|                       3|\n",
      "|  1|pawan| 24|         2|                       4|\n",
      "|  2|    d| 36|         3|                       5|\n",
      "+---+-----+---+----------+------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/25 20:41:46 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , names, age, experience\n",
      " Schema: _c0, names, age, experience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/dsaipawan/Documents/python-learing/big-data/test1.csv\n"
     ]
    }
   ],
   "source": [
    "df_new_clm = df.withColumn('Experience after 2 years', df['experience'] + 2)\n",
    "df_new_clm.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Droping the Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+----------+\n",
      "|_c0|names|age|experience|\n",
      "+---+-----+---+----------+\n",
      "|  0|  sai| 12|         1|\n",
      "|  1|pawan| 24|         2|\n",
      "|  2|    d| 36|         3|\n",
      "+---+-----+---+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/25 20:41:47 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , names, age, experience\n",
      " Schema: _c0, names, age, experience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/dsaipawan/Documents/python-learing/big-data/test1.csv\n"
     ]
    }
   ],
   "source": [
    "df_new_clm.drop('Experience after 2 years').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming the Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+----------+\n",
      "|_c0| name|age|experience|\n",
      "+---+-----+---+----------+\n",
      "|  0|  sai| 12|         1|\n",
      "|  1|pawan| 24|         2|\n",
      "|  2|    d| 36|         3|\n",
      "+---+-----+---+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/25 20:41:47 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , names, age, experience\n",
      " Schema: _c0, names, age, experience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/dsaipawan/Documents/python-learing/big-data/test1.csv\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed('names', 'name').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new rows using Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+----+----------+\n",
      "| _c0|   names| age|experience|\n",
      "+----+--------+----+----------+\n",
      "|   3|saipawan|  34|         4|\n",
      "|   4|  pawand|NULL|         5|\n",
      "|   5|    said|NULL|      NULL|\n",
      "|NULL|    NULL|NULL|      NULL|\n",
      "+----+--------+----+----------+\n",
      "\n",
      "+----+--------+----+----------+\n",
      "| _c0|   names| age|experience|\n",
      "+----+--------+----+----------+\n",
      "|   0|     sai|  12|         1|\n",
      "|   1|   pawan|  24|         2|\n",
      "|   2|       d|  36|         3|\n",
      "|   3|saipawan|  34|         4|\n",
      "|   4|  pawand|NULL|         5|\n",
      "|   5|    said|NULL|      NULL|\n",
      "|NULL|    NULL|NULL|      NULL|\n",
      "+----+--------+----+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/25 20:41:47 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , names, age, experience\n",
      " Schema: _c0, names, age, experience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/dsaipawan/Documents/python-learing/big-data/test1.csv\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "new_rows = spark.createDataFrame(\n",
    "    [\n",
    "        (3, 'saipawan', 34, 4),\n",
    "        (4, 'pawand', None, 5),\n",
    "        (5, 'said', None, None),\n",
    "        (None, None, None, None)\n",
    "    ],\n",
    "     df.columns\n",
    "    )\n",
    "new_rows.show()\n",
    "\n",
    "df = df.union(new_rows)\n",
    "\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/25 20:41:47 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , names, age, experience\n",
      " Schema: _c0, names, age, experience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/dsaipawan/Documents/python-learing/big-data/test1.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+----+----------+\n",
      "| _c0|   names| age|experience|\n",
      "+----+--------+----+----------+\n",
      "|   0|     sai|  12|         1|\n",
      "|   1|   pawan|  24|         2|\n",
      "|   2|       d|  36|         3|\n",
      "|   3|saipawan|  34|         4|\n",
      "|   4|  pawand|NULL|         5|\n",
      "|   5|    said|NULL|      NULL|\n",
      "|NULL|    NULL|NULL|      NULL|\n",
      "+----+--------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Droping Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/25 20:41:47 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , names, age, experience\n",
      " Schema: _c0, names, age, experience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/dsaipawan/Documents/python-learing/big-data/test1.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+----------+\n",
      "|_c0|   names|age|experience|\n",
      "+---+--------+---+----------+\n",
      "|  0|     sai| 12|         1|\n",
      "|  1|   pawan| 24|         2|\n",
      "|  2|       d| 36|         3|\n",
      "|  3|saipawan| 34|         4|\n",
      "+---+--------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This will drop all the rows with Null values in it.\n",
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/25 20:41:47 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , names, age, experience\n",
      " Schema: _c0, names, age, experience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/dsaipawan/Documents/python-learing/big-data/test1.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----+----------+\n",
      "|_c0|   names| age|experience|\n",
      "+---+--------+----+----------+\n",
      "|  0|     sai|  12|         1|\n",
      "|  1|   pawan|  24|         2|\n",
      "|  2|       d|  36|         3|\n",
      "|  3|saipawan|  34|         4|\n",
      "|  4|  pawand|NULL|         5|\n",
      "|  5|    said|NULL|      NULL|\n",
      "+---+--------+----+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/25 20:41:48 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , names, age, experience\n",
      " Schema: _c0, names, age, experience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/dsaipawan/Documents/python-learing/big-data/test1.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+----------+\n",
      "|_c0|   names|age|experience|\n",
      "+---+--------+---+----------+\n",
      "|  0|     sai| 12|         1|\n",
      "|  1|   pawan| 24|         2|\n",
      "|  2|       d| 36|         3|\n",
      "|  3|saipawan| 34|         4|\n",
      "+---+--------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(how='all').show()\n",
    "\n",
    "df.na.drop(how='any').show()  # this is the default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----+----------+\n",
      "|_c0|   names| age|experience|\n",
      "+---+--------+----+----------+\n",
      "|  0|     sai|  12|         1|\n",
      "|  1|   pawan|  24|         2|\n",
      "|  2|       d|  36|         3|\n",
      "|  3|saipawan|  34|         4|\n",
      "|  4|  pawand|NULL|         5|\n",
      "|  5|    said|NULL|      NULL|\n",
      "+---+--------+----+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/25 20:41:48 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , names, age, experience\n",
      " Schema: _c0, names, age, experience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/dsaipawan/Documents/python-learing/big-data/test1.csv\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(how='any',thresh=2).show()\n",
    "# This will delete all the rows with dosent have more than <thresh> non null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/25 20:41:48 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , names, age, experience\n",
      " Schema: _c0, names, age, experience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/dsaipawan/Documents/python-learing/big-data/test1.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----+----------+\n",
      "|_c0|   names| age|experience|\n",
      "+---+--------+----+----------+\n",
      "|  0|     sai|  12|         1|\n",
      "|  1|   pawan|  24|         2|\n",
      "|  2|       d|  36|         3|\n",
      "|  3|saipawan|  34|         4|\n",
      "|  4|  pawand|NULL|         5|\n",
      "+---+--------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(how='any', subset=['experience']).show()\n",
    "# Specify which columns you want to focus on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/25 20:41:48 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , names, age, experience\n",
      " Schema: _c0, names, age, experience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/dsaipawan/Documents/python-learing/big-data/test1.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+----+----------+\n",
      "| _c0|   names| age|experience|\n",
      "+----+--------+----+----------+\n",
      "|   0|     sai|  12|         1|\n",
      "|   1|   pawan|  24|         2|\n",
      "|   2|       d|  36|         3|\n",
      "|   3|saipawan|  34|         4|\n",
      "|   4|  pawand|NULL|         5|\n",
      "|   5|    said|NULL|      NULL|\n",
      "|NULL|    NULL|NULL|      NULL|\n",
      "+----+--------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill('missing values', subset=['age', 'experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+----+----------+----------+-----------------+\n",
      "| _c0|   names| age|experience|age_impute|experience_impute|\n",
      "+----+--------+----+----------+----------+-----------------+\n",
      "|   0|     sai|  12|         1|        12|                1|\n",
      "|   1|   pawan|  24|         2|        24|                2|\n",
      "|   2|       d|  36|         3|        36|                3|\n",
      "|   3|saipawan|  34|         4|        34|                4|\n",
      "|   4|  pawand|NULL|         5|        26|                5|\n",
      "|   5|    said|NULL|      NULL|        26|                3|\n",
      "|NULL|    NULL|NULL|      NULL|        26|                3|\n",
      "+----+--------+----+----------+----------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/25 20:41:59 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , names, age, experience\n",
      " Schema: _c0, names, age, experience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/dsaipawan/Documents/python-learing/big-data/test1.csv\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "cols = ['age', 'experience']\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols = cols,\n",
    "    outputCols = [ f'{col}_impute' for col in cols]\n",
    ").setStrategy('mean')\n",
    "\n",
    "imputer.fit(df).transform(df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter on DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/25 20:55:37 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , names, age, experience\n",
      " Schema: _c0, names, age, experience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/dsaipawan/Documents/python-learing/big-data/test1.csv\n",
      "24/02/25 20:55:37 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , names, age, experience\n",
      " Schema: _c0, names, age, experience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/dsaipawan/Documents/python-learing/big-data/test1.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+----+----------+\n",
      "| _c0|   names| age|experience|\n",
      "+----+--------+----+----------+\n",
      "|   0|     sai|  12|         1|\n",
      "|   1|   pawan|  24|         2|\n",
      "|   2|       d|  36|         3|\n",
      "|   3|saipawan|  34|         4|\n",
      "|   4|  pawand|NULL|         5|\n",
      "|   5|    said|NULL|      NULL|\n",
      "|NULL|    NULL|NULL|      NULL|\n",
      "+----+--------+----+----------+\n",
      "\n",
      "+---+--------+---+----------+\n",
      "|_c0|   names|age|experience|\n",
      "+---+--------+---+----------+\n",
      "|  1|   pawan| 24|         2|\n",
      "|  3|saipawan| 34|         4|\n",
      "+---+--------+---+----------+\n",
      "\n",
      "+---+--------+---+----------+\n",
      "|_c0|   names|age|experience|\n",
      "+---+--------+---+----------+\n",
      "|  1|   pawan| 24|         2|\n",
      "|  2|       d| 36|         3|\n",
      "|  3|saipawan| 34|         4|\n",
      "+---+--------+---+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/25 20:55:37 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , names, age, experience\n",
      " Schema: _c0, names, age, experience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/dsaipawan/Documents/python-learing/big-data/test1.csv\n"
     ]
    }
   ],
   "source": [
    "df.show()\n",
    "\n",
    "\n",
    "df.filter(\n",
    "    (df['age'] > 15) & (df['age'] < 35)\n",
    ").show()\n",
    "# other operations are &,|, ==, ~\n",
    "\n",
    "df.filter(\n",
    "    ~(df['age'] < 15)\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GroupBy and Aggrigate Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+------+\n",
      "|     Name|  Department|Salary|\n",
      "+---------+------------+------+\n",
      "|    Krish|Data Science| 10000|\n",
      "|    Krish|         IOT|  5000|\n",
      "|   Mahesh|    Big Data|  4000|\n",
      "|    Krish|    Big Data|  4000|\n",
      "|   Mahesh|Data Science|  3000|\n",
      "|Sudhanshu|Data Science| 20000|\n",
      "|Sudhanshu|         IOT| 10000|\n",
      "|Sudhanshu|    Big Data|  5000|\n",
      "|    Sunny|Data Science| 10000|\n",
      "|    Sunny|    Big Data|  2000|\n",
      "+---------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [['Krish', 'Data Science', 10000],\n",
    "['Krish', 'IOT', 5000],\n",
    "['Mahesh', 'Big Data', 4000],\n",
    "['Krish', 'Big Data', 4000],\n",
    "['Mahesh', 'Data Science', 3000],\n",
    "['Sudhanshu', 'Data Science', 20000],\n",
    "['Sudhanshu', 'IOT', 10000],\n",
    "['Sudhanshu', 'Big Data', 5000],\n",
    "['Sunny', 'Data Science', 10000],\n",
    "['Sunny', 'Big Data', 2000]]\n",
    "\n",
    "df = spark.createDataFrame(data, ['Name', 'Department', 'Salary'],)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|     Name|sum(Salary)|\n",
      "+---------+-----------+\n",
      "|    Krish|      19000|\n",
      "|   Mahesh|       7000|\n",
      "|Sudhanshu|      35000|\n",
      "|    Sunny|      12000|\n",
      "+---------+-----------+\n",
      "\n",
      "+------------+-----------+\n",
      "|  Department|avg(Salary)|\n",
      "+------------+-----------+\n",
      "|    Big Data|     3750.0|\n",
      "|         IOT|     7500.0|\n",
      "|Data Science|    10750.0|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Name').sum().show()\n",
    "\n",
    "df.groupBy('Department').avg().sort('avg(Salary)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|max(Salary)|\n",
      "+-----------+\n",
      "|      20000|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg({'Salary':'max'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big_data_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
